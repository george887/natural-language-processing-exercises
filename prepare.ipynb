{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire as a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://codeup.com/introducing-salary-refund-guarantee/',\n",
       " 'https://codeup.com/codeups-application-process/',\n",
       " 'https://codeup.com/what-is-python/',\n",
       " 'https://codeup.com/what-is-machine-learning/',\n",
       " 'https://codeup.com/covid-19-data-challenge/',\n",
       " 'https://codeup.com/codeup-in-houston/',\n",
       " 'https://codeup.com/how-were-celebrating-world-mental-health-day-from-home/',\n",
       " 'https://codeup.com/succeed-in-a-coding-bootcamp/',\n",
       " 'https://codeup.com/transition-into-data-science/',\n",
       " 'https://codeup.com/from-slacker-to-data-scientist/',\n",
       " 'https://codeup.com/new-scholarship/',\n",
       " 'https://codeup.com/education-is-an-investment/',\n",
       " 'https://codeup.com/what-to-expect-at-codeup/',\n",
       " 'https://codeup.com/codeup-alumni-make-water/',\n",
       " 'https://codeup.com/codeup-inc-5000/',\n",
       " 'https://codeup.com/what-data-science-career-is-for-you/',\n",
       " 'https://codeup.com/build-your-career-in-tech/',\n",
       " 'https://codeup.com/journey-into-web-development/',\n",
       " 'https://codeup.com/math-in-data-science/',\n",
       " 'https://codeup.com/codeup-wins-civtech-datathon/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = a.get_all_urls()\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/', 'https://codeup.com/data-science-myths/', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original DF\n",
    "original = a.get_blog_articles(urls, cached=False)\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2438\n",
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoor’s #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. we’ve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing web dev program. we’re focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeup’s first data science cohort, which will start class on february 4, 2019. hurry – there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at the content and lower casing\n",
    "article = original.content[0].lower()\n",
    "print(len(article))\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429\n",
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoors #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. weve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program. were focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning  regression; 6) supervised machine learning  classification; 7) unsupervised machine learning  clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeups first data science cohort, which will start class on february 4, 2019. hurry  there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize unicode characters. Gets rid of the funky text like \\xa0glassdoor’s in line 3\n",
    "article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(len(article))\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2338\n",
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america\n",
      "data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry\n",
      "our program will be 18 weeks long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce\n",
      "we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning  regression 6 supervised machine learning  classification 7 unsupervised machine learning  clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development\n",
      "applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry  there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio\n",
      "if you want to learn about joining our program or hiring our graduates email datasciencecodeupcom\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "print(len(article))\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    '''\n",
    "    Takes in the original DF of articles. You set the index of which article you would like to clean\n",
    "    '''\n",
    "    # Selecting the orginal df and its corresponding index then lower casing\n",
    "    article = original.content[0].lower()\n",
    "    \n",
    "    # Normalize unicode characters. Gets rid of the funky text like \\xa0glassdoor’s in line 3\n",
    "    article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "    article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "    article = re.sub(r'\\n', '', article)\n",
    "    \n",
    "    return article\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2331\n",
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in americadata science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industryour program will be 18 weeks long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforcewe focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning  regression 6 supervised machine learning  classification 7 unsupervised machine learning  clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise developmentapplications are now open for codeups first data science cohort which will start class on february 4 2019 hurry  there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonioif you want to learn about joining our program or hiring our graduates email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "article = basic_clean(original)\n",
    "print(len(article))\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization - is when you split larger strings of text into smaller pieces or tokens by setting a boundary. You might chunk a sentence into words using a space as a boundary or a paragraph into sentences using punctuation as a boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326\n",
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in americadata science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industryour program will be 18 weeks long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforcewe focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise developmentapplications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonioif you want to learn about joining our program or hiring our graduates email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(len(tokenizer.tokenize(article, return_str=True)))\n",
    "print(tokenizer.tokenize(article, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a tokenized string.\n",
    "    '''\n",
    "    # Create tokenizer.\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    \n",
    "    # Use tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str=True)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326\n",
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in americadata science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industryour program will be 18 weeks long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforcewe focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise developmentapplications are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonioif you want to learn about joining our program or hiring our graduates email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenize(article)))\n",
    "print(tokenize(article))\n",
    "article = tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is when you reduce related words in your text to their common stem. It can make it easier when you are searching for a particular word in your text to search for their common stem rather than every form of the word. Stemmers aren't that sophisticated in the way they chop off word endings at their common stems; Spacy, another python NLP library, doesn't even include a stemmer in their library. Spacy only offers the more sophisticated lemmatizer, which we will look at in NLTK next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create porter stemmer.\n",
    "\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "ps.stem('call'), ps.stem('called'), ps.stem('calling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'rumors',\n",
       " 'are',\n",
       " 'true',\n",
       " 'the',\n",
       " 'time',\n",
       " 'has',\n",
       " 'arrived',\n",
       " 'codeup',\n",
       " 'has',\n",
       " 'officially',\n",
       " 'opened',\n",
       " 'applications',\n",
       " 'to',\n",
       " 'our',\n",
       " 'new',\n",
       " 'data',\n",
       " 'science',\n",
       " 'career',\n",
       " 'accelerator',\n",
       " 'with',\n",
       " 'only',\n",
       " '25',\n",
       " 'seats',\n",
       " 'available',\n",
       " 'this',\n",
       " 'immersive',\n",
       " 'program',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'a',\n",
       " 'kind',\n",
       " 'in',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'and',\n",
       " 'will',\n",
       " 'help',\n",
       " 'you',\n",
       " 'land',\n",
       " 'a',\n",
       " 'job',\n",
       " 'in',\n",
       " 'glassdoors',\n",
       " '1',\n",
       " 'best',\n",
       " 'job',\n",
       " 'in',\n",
       " 'americadata',\n",
       " 'science',\n",
       " 'is',\n",
       " 'a',\n",
       " 'method',\n",
       " 'of',\n",
       " 'providing',\n",
       " 'actionable',\n",
       " 'intelligence',\n",
       " 'from',\n",
       " 'data',\n",
       " 'the',\n",
       " 'data',\n",
       " 'revolution',\n",
       " 'has',\n",
       " 'hit',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'resulting',\n",
       " 'in',\n",
       " 'an',\n",
       " 'explosion',\n",
       " 'in',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'positions',\n",
       " 'across',\n",
       " 'companies',\n",
       " 'like',\n",
       " 'usaa',\n",
       " 'accenture',\n",
       " 'booz',\n",
       " 'allen',\n",
       " 'hamilton',\n",
       " 'and',\n",
       " 'heb',\n",
       " 'weve',\n",
       " 'even',\n",
       " 'seen',\n",
       " 'utsa',\n",
       " 'invest',\n",
       " '70',\n",
       " 'm',\n",
       " 'for',\n",
       " 'a',\n",
       " 'cybersecurity',\n",
       " 'center',\n",
       " 'and',\n",
       " 'school',\n",
       " 'of',\n",
       " 'data',\n",
       " 'science',\n",
       " 'we',\n",
       " 'built',\n",
       " 'a',\n",
       " 'program',\n",
       " 'to',\n",
       " 'specifically',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'growing',\n",
       " 'demands',\n",
       " 'of',\n",
       " 'this',\n",
       " 'industryour',\n",
       " 'program',\n",
       " 'will',\n",
       " 'be',\n",
       " '18',\n",
       " 'weeks',\n",
       " 'long',\n",
       " 'fulltime',\n",
       " 'handson',\n",
       " 'and',\n",
       " 'projectbased',\n",
       " 'our',\n",
       " 'curriculum',\n",
       " 'development',\n",
       " 'and',\n",
       " 'instruction',\n",
       " 'is',\n",
       " 'led',\n",
       " 'by',\n",
       " 'senior',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'maggie',\n",
       " 'giust',\n",
       " 'who',\n",
       " 'has',\n",
       " 'worked',\n",
       " 'at',\n",
       " 'heb',\n",
       " 'capital',\n",
       " 'group',\n",
       " 'and',\n",
       " 'rackspace',\n",
       " 'along',\n",
       " 'with',\n",
       " 'input',\n",
       " 'from',\n",
       " 'dozens',\n",
       " 'of',\n",
       " 'practitioners',\n",
       " 'and',\n",
       " 'hiring',\n",
       " 'partners',\n",
       " 'students',\n",
       " 'will',\n",
       " 'work',\n",
       " 'with',\n",
       " 'real',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'realistic',\n",
       " 'problems',\n",
       " 'and',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'data',\n",
       " 'science',\n",
       " 'pipeline',\n",
       " 'from',\n",
       " 'collection',\n",
       " 'to',\n",
       " 'deployment',\n",
       " 'they',\n",
       " 'will',\n",
       " 'receive',\n",
       " 'professional',\n",
       " 'development',\n",
       " 'training',\n",
       " 'in',\n",
       " 'resume',\n",
       " 'writing',\n",
       " 'interviewing',\n",
       " 'and',\n",
       " 'continuing',\n",
       " 'education',\n",
       " 'to',\n",
       " 'prepare',\n",
       " 'for',\n",
       " 'a',\n",
       " 'smooth',\n",
       " 'transition',\n",
       " 'to',\n",
       " 'the',\n",
       " 'workforcewe',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'applied',\n",
       " 'data',\n",
       " 'science',\n",
       " 'for',\n",
       " 'immediate',\n",
       " 'impact',\n",
       " 'and',\n",
       " 'roi',\n",
       " 'in',\n",
       " 'a',\n",
       " 'business',\n",
       " 'which',\n",
       " 'is',\n",
       " 'how',\n",
       " 'we',\n",
       " 'can',\n",
       " 'back',\n",
       " 'it',\n",
       " 'all',\n",
       " 'up',\n",
       " 'with',\n",
       " 'a',\n",
       " '6',\n",
       " 'month',\n",
       " 'tuition',\n",
       " 'refund',\n",
       " 'guarantee',\n",
       " 'just',\n",
       " 'like',\n",
       " 'our',\n",
       " 'existing',\n",
       " 'web',\n",
       " 'dev',\n",
       " 'program',\n",
       " 'were',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'data',\n",
       " 'science',\n",
       " 'with',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'and',\n",
       " 'ml',\n",
       " 'covered',\n",
       " 'in',\n",
       " '14',\n",
       " 'modules',\n",
       " '1',\n",
       " 'fundamentals',\n",
       " '2',\n",
       " 'applied',\n",
       " 'statistics',\n",
       " '3',\n",
       " 'sql',\n",
       " '4',\n",
       " 'python',\n",
       " '5',\n",
       " 'supervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'regression',\n",
       " '6',\n",
       " 'supervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'classification',\n",
       " '7',\n",
       " 'unsupervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'clustering',\n",
       " '8',\n",
       " 'time',\n",
       " 'series',\n",
       " 'analysis',\n",
       " '9',\n",
       " 'anomaly',\n",
       " 'detection',\n",
       " '10',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '11',\n",
       " 'distributed',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '12',\n",
       " 'advanced',\n",
       " 'topics',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'nosql',\n",
       " 'cloud',\n",
       " 'deployment',\n",
       " 'etc',\n",
       " '13',\n",
       " 'storytelling',\n",
       " 'with',\n",
       " 'data',\n",
       " 'and',\n",
       " '14',\n",
       " 'domain',\n",
       " 'expertise',\n",
       " 'developmentapplications',\n",
       " 'are',\n",
       " 'now',\n",
       " 'open',\n",
       " 'for',\n",
       " 'codeups',\n",
       " 'first',\n",
       " 'data',\n",
       " 'science',\n",
       " 'cohort',\n",
       " 'which',\n",
       " 'will',\n",
       " 'start',\n",
       " 'class',\n",
       " 'on',\n",
       " 'february',\n",
       " '4',\n",
       " '2019',\n",
       " 'hurry',\n",
       " 'there',\n",
       " 'are',\n",
       " 'only',\n",
       " '25',\n",
       " 'seats',\n",
       " 'available',\n",
       " 'to',\n",
       " 'further',\n",
       " 'our',\n",
       " 'mission',\n",
       " 'of',\n",
       " 'cultivating',\n",
       " 'inclusive',\n",
       " 'growth',\n",
       " 'scholarships',\n",
       " 'will',\n",
       " 'be',\n",
       " 'available',\n",
       " 'to',\n",
       " 'women',\n",
       " 'minorities',\n",
       " 'lgbtqia',\n",
       " 'individuals',\n",
       " 'veterans',\n",
       " 'first',\n",
       " 'responders',\n",
       " 'and',\n",
       " 'people',\n",
       " 'relocating',\n",
       " 'to',\n",
       " 'san',\n",
       " 'antonioif',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'joining',\n",
       " 'our',\n",
       " 'program',\n",
       " 'or',\n",
       " 'hiring',\n",
       " 'our',\n",
       " 'graduates',\n",
       " 'email',\n",
       " 'datasciencecodeupcom']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033\n",
      "the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career acceler with onli 25 seat avail thi immers program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in americadata scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explos in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industryour program will be 18 week long fulltim handson and projectbas our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practition and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profession develop train in resum write interview and continu educ to prepar for a smooth transit to the workforcew focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarante just like our exist web dev program were focus on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain expertis developmentappl are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclus growth scholarship will be avail to women minor lgbtqia individu veteran first respond and peopl reloc to san antonioif you want to learn about join our program or hire our graduat email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "# Now we can apply this stemming transformation to all the words in the article.\n",
    "# split() creates a list of all the words in the article\n",
    "stems = [ps.stem(word) for word in article.split()]\n",
    "\n",
    "# Join our lists of words into a string again; assign to a variable to save changes\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(len(article_stemmed))\n",
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''\n",
    "    This function takes in a string and\n",
    "    returns a string with words stemmed.\n",
    "    '''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    # Use the stemmer to stem each word in the list of words we created by using split.\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    \n",
    "    # Join our lists of words into a string again and assign to a variable.\n",
    "    string = ' '.join(stems)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career accel with onli 25 seat avail thi immer program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in americadata scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explo in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industryour program will be 18 week long fulltim handson and projectba our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practit and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profess develop train in resum write interview and continu educ to prepar for a smooth transit to the workforcew focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarant just like our exist web dev program were focu on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervi machin learn regress 6 supervi machin learn classif 7 unsupervi machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain experti developmentappl are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclu growth scholarship will be avail to women minor lgbtqia individu veteran first respond and peopl reloc to san antonioif you want to learn about join our program or hire our graduat email datasciencecodeupcom'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(stem(article_stemmed)))\n",
    "stem(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and       13\n",
       "data      12\n",
       "to         9\n",
       "a          8\n",
       "in         8\n",
       "scienc     7\n",
       "our        6\n",
       "learn      6\n",
       "of         6\n",
       "with       6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization - is when you reduce related words in your text to their lemma or word base by applying a morphological analysis to your text. Like stemming, this is done to reduce the number of forms you have of the same word, so they can be analyzed as a single item. While stemming might create tokens that are not actually words anymore after they have been chopped off at their base, lemmatization will leave you with real words. A drawback to lemmatization is that it takes longer than stemming; you can try both to see which gives you better results as you analyze a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: studi -- lemma: study\n",
      "stem: studi -- lemma: study\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for word in 'study studies'.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'rumor',\n",
       " 'are',\n",
       " 'true',\n",
       " 'the',\n",
       " 'time',\n",
       " 'ha',\n",
       " 'arriv',\n",
       " 'codeup',\n",
       " 'ha',\n",
       " 'offici',\n",
       " 'open',\n",
       " 'applic',\n",
       " 'to',\n",
       " 'our',\n",
       " 'new',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'career',\n",
       " 'acceler',\n",
       " 'with',\n",
       " 'onli',\n",
       " '25',\n",
       " 'seat',\n",
       " 'avail',\n",
       " 'thi',\n",
       " 'immers',\n",
       " 'program',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'a',\n",
       " 'kind',\n",
       " 'in',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'and',\n",
       " 'will',\n",
       " 'help',\n",
       " 'you',\n",
       " 'land',\n",
       " 'a',\n",
       " 'job',\n",
       " 'in',\n",
       " 'glassdoor',\n",
       " '1',\n",
       " 'best',\n",
       " 'job',\n",
       " 'in',\n",
       " 'americadata',\n",
       " 'scienc',\n",
       " 'is',\n",
       " 'a',\n",
       " 'method',\n",
       " 'of',\n",
       " 'provid',\n",
       " 'action',\n",
       " 'intellig',\n",
       " 'from',\n",
       " 'data',\n",
       " 'the',\n",
       " 'data',\n",
       " 'revolut',\n",
       " 'ha',\n",
       " 'hit',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'result',\n",
       " 'in',\n",
       " 'an',\n",
       " 'explos',\n",
       " 'in',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'posit',\n",
       " 'across',\n",
       " 'compani',\n",
       " 'like',\n",
       " 'usaa',\n",
       " 'accentur',\n",
       " 'booz',\n",
       " 'allen',\n",
       " 'hamilton',\n",
       " 'and',\n",
       " 'heb',\n",
       " 'weve',\n",
       " 'even',\n",
       " 'seen',\n",
       " 'utsa',\n",
       " 'invest',\n",
       " '70',\n",
       " 'm',\n",
       " 'for',\n",
       " 'a',\n",
       " 'cybersecur',\n",
       " 'center',\n",
       " 'and',\n",
       " 'school',\n",
       " 'of',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'we',\n",
       " 'built',\n",
       " 'a',\n",
       " 'program',\n",
       " 'to',\n",
       " 'specif',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'grow',\n",
       " 'demand',\n",
       " 'of',\n",
       " 'thi',\n",
       " 'industryour',\n",
       " 'program',\n",
       " 'will',\n",
       " 'be',\n",
       " '18',\n",
       " 'week',\n",
       " 'long',\n",
       " 'fulltim',\n",
       " 'handson',\n",
       " 'and',\n",
       " 'projectbas',\n",
       " 'our',\n",
       " 'curriculum',\n",
       " 'develop',\n",
       " 'and',\n",
       " 'instruct',\n",
       " 'is',\n",
       " 'led',\n",
       " 'by',\n",
       " 'senior',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'maggi',\n",
       " 'giust',\n",
       " 'who',\n",
       " 'ha',\n",
       " 'work',\n",
       " 'at',\n",
       " 'heb',\n",
       " 'capit',\n",
       " 'group',\n",
       " 'and',\n",
       " 'rackspac',\n",
       " 'along',\n",
       " 'with',\n",
       " 'input',\n",
       " 'from',\n",
       " 'dozen',\n",
       " 'of',\n",
       " 'practition',\n",
       " 'and',\n",
       " 'hire',\n",
       " 'partner',\n",
       " 'student',\n",
       " 'will',\n",
       " 'work',\n",
       " 'with',\n",
       " 'real',\n",
       " 'data',\n",
       " 'set',\n",
       " 'realist',\n",
       " 'problem',\n",
       " 'and',\n",
       " 'the',\n",
       " 'entir',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'pipelin',\n",
       " 'from',\n",
       " 'collect',\n",
       " 'to',\n",
       " 'deploy',\n",
       " 'they',\n",
       " 'will',\n",
       " 'receiv',\n",
       " 'profession',\n",
       " 'develop',\n",
       " 'train',\n",
       " 'in',\n",
       " 'resum',\n",
       " 'write',\n",
       " 'interview',\n",
       " 'and',\n",
       " 'continu',\n",
       " 'educ',\n",
       " 'to',\n",
       " 'prepar',\n",
       " 'for',\n",
       " 'a',\n",
       " 'smooth',\n",
       " 'transit',\n",
       " 'to',\n",
       " 'the',\n",
       " 'workforcew',\n",
       " 'focu',\n",
       " 'on',\n",
       " 'appli',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'for',\n",
       " 'immedi',\n",
       " 'impact',\n",
       " 'and',\n",
       " 'roi',\n",
       " 'in',\n",
       " 'a',\n",
       " 'busi',\n",
       " 'which',\n",
       " 'is',\n",
       " 'how',\n",
       " 'we',\n",
       " 'can',\n",
       " 'back',\n",
       " 'it',\n",
       " 'all',\n",
       " 'up',\n",
       " 'with',\n",
       " 'a',\n",
       " '6',\n",
       " 'month',\n",
       " 'tuition',\n",
       " 'refund',\n",
       " 'guarante',\n",
       " 'just',\n",
       " 'like',\n",
       " 'our',\n",
       " 'exist',\n",
       " 'web',\n",
       " 'dev',\n",
       " 'program',\n",
       " 'were',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'with',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'and',\n",
       " 'ml',\n",
       " 'cover',\n",
       " 'in',\n",
       " '14',\n",
       " 'modul',\n",
       " '1',\n",
       " 'fundament',\n",
       " '2',\n",
       " 'appli',\n",
       " 'statist',\n",
       " '3',\n",
       " 'sql',\n",
       " '4',\n",
       " 'python',\n",
       " '5',\n",
       " 'supervis',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'regress',\n",
       " '6',\n",
       " 'supervis',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'classif',\n",
       " '7',\n",
       " 'unsupervis',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'cluster',\n",
       " '8',\n",
       " 'time',\n",
       " 'seri',\n",
       " 'analysi',\n",
       " '9',\n",
       " 'anomali',\n",
       " 'detect',\n",
       " '10',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " '11',\n",
       " 'distribut',\n",
       " 'machin',\n",
       " 'learn',\n",
       " '12',\n",
       " 'advanc',\n",
       " 'topic',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'nosql',\n",
       " 'cloud',\n",
       " 'deploy',\n",
       " 'etc',\n",
       " '13',\n",
       " 'storytel',\n",
       " 'with',\n",
       " 'data',\n",
       " 'and',\n",
       " '14',\n",
       " 'domain',\n",
       " 'expertis',\n",
       " 'developmentappl',\n",
       " 'are',\n",
       " 'now',\n",
       " 'open',\n",
       " 'for',\n",
       " 'codeup',\n",
       " 'first',\n",
       " 'data',\n",
       " 'scienc',\n",
       " 'cohort',\n",
       " 'which',\n",
       " 'will',\n",
       " 'start',\n",
       " 'class',\n",
       " 'on',\n",
       " 'februari',\n",
       " '4',\n",
       " '2019',\n",
       " 'hurri',\n",
       " 'there',\n",
       " 'are',\n",
       " 'onli',\n",
       " '25',\n",
       " 'seat',\n",
       " 'avail',\n",
       " 'to',\n",
       " 'further',\n",
       " 'our',\n",
       " 'mission',\n",
       " 'of',\n",
       " 'cultiv',\n",
       " 'inclus',\n",
       " 'growth',\n",
       " 'scholarship',\n",
       " 'will',\n",
       " 'be',\n",
       " 'avail',\n",
       " 'to',\n",
       " 'woman',\n",
       " 'minor',\n",
       " 'lgbtqia',\n",
       " 'individu',\n",
       " 'veteran',\n",
       " 'first',\n",
       " 'respond',\n",
       " 'and',\n",
       " 'peopl',\n",
       " 'reloc',\n",
       " 'to',\n",
       " 'san',\n",
       " 'antonioif',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'join',\n",
       " 'our',\n",
       " 'program',\n",
       " 'or',\n",
       " 'hire',\n",
       " 'our',\n",
       " 'graduat',\n",
       " 'email',\n",
       " 'datasciencecodeupcom']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the lemmatizer on each word in the list of words we created by using split.\n",
    "\n",
    "lemmas = [wnl.lemmatize(word) for word in article_stemmed.split()]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career acceler with onli 25 seat avail thi immers program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in americadata scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explos in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industryour program will be 18 week long fulltim handson and projectbas our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practition and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profession develop train in resum write interview and continu educ to prepar for a smooth transit to the workforcew focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarante just like our exist web dev program were focus on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain expertis developmentappl are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclus growth scholarship will be avail to woman minor lgbtqia individu veteran first respond and peopl reloc to san antonioif you want to learn about join our program or hire our graduat email datasciencecodeupcom'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join our list of words into a string again; assign to a variable to save changes.\n",
    "\n",
    "article_stemmed = ' '.join(lemmas)\n",
    "print(len(article_stemmed))\n",
    "article_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''\n",
    "    This function takes in string for and\n",
    "    returns a string with words lemmatized.\n",
    "    '''\n",
    "    # Create the lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # Use the lemmatizer on each word in the list of words we created by using split.\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    # Join our list of words into a string again and assign to a variable.\n",
    "    string = ' '.join(lemmas)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career acceler with onli 25 seat avail thi immers program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in americadata scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explos in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industryour program will be 18 week long fulltim handson and projectbas our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practition and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profession develop train in resum write interview and continu educ to prepar for a smooth transit to the workforcew focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarante just like our exist web dev program were focus on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain expertis developmentappl are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclus growth scholarship will be avail to woman minor lgbtqia individu veteran first respond and peopl reloc to san antonioif you want to learn about join our program or hire our graduat email datasciencecodeupcom'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_lemmatize = lemmatize(article_stemmed)\n",
    "print(len(article_lemmatize))\n",
    "article_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and        13\n",
       "data       12\n",
       "to          9\n",
       "a           8\n",
       "in          8\n",
       "           ..\n",
       "how         1\n",
       "input       1\n",
       "at          1\n",
       "languag     1\n",
       "long        1\n",
       "Length: 232, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now that we have a list of the lemmas, we can take a look at the most frequent words.\n",
    "pd.Series(lemmas).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Words - Words which have little or no significance, especially when constructing meaningful features from text, are known as stop words (or stopwords). These are usually words that end up having the maximum frequency if you do a simple term or word frequency in a corpus. Typically, these can be articles, conjunctions, prepositions and so on. Some examples of stopwords: a, an, the, and like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list of stopwords.\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'rumor', 'are', 'true', 'the', 'time', 'ha', 'arriv', 'codeup', 'ha']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split words in lemmatized column.\n",
    "\n",
    "words = article_lemmatize.split()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 111 stopwords\n",
      "---\n",
      "rumor true time ha arriv codeup ha offici open applic new data scienc career acceler onli 25 seat avail thi immers program one kind san antonio help land job glassdoor 1 best job americadata scienc method provid action intellig data data revolut ha hit san antonio result explos data scientist posit across compani like usaa accentur booz allen hamilton heb weve even seen utsa invest 70 cybersecur center school data scienc built program specif meet grow demand thi industryour program 18 week long fulltim handson projectbas curriculum develop instruct led senior data scientist maggi giust ha work heb capit group rackspac along input dozen practition hire partner student work real data set realist problem entir data scienc pipelin collect deploy receiv profession develop train resum write interview continu educ prepar smooth transit workforcew focu appli data scienc immedi impact roi busi back 6 month tuition refund guarante like exist web dev program focus data scienc python sql ml cover 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel data 14 domain expertis developmentappl open codeup first data scienc cohort start class februari 4 2019 hurri onli 25 seat avail mission cultiv inclus growth scholarship avail woman minor lgbtqia individu veteran first respond peopl reloc san antonioif want learn join program hire graduat email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "# Create a list of words from my string with stopwords removed and assign to variable.\n",
    "filtered_words = [word for word in words if word not in stopword_list]\n",
    "\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')\n",
    "\n",
    "# Join words in the list back into strings; assign to a variable to keep changes.\n",
    "article_without_stopwords = ' '.join(filtered_words)\n",
    "\n",
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    '''\n",
    "    This function takes in a string, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns a string.\n",
    "    '''\n",
    "    # Create stopword_list.\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "\n",
    "    # Add in 'extra_words' to stopword_list.\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rumor true time ha arriv codeup ha offici open applic new data scienc career acceler onli 25 seat avail thi immers program one kind san antonio help land job glassdoor 1 best job americadata scienc method provid action intellig data data revolut ha hit san antonio result explos data scientist posit across compani like usaa accentur booz allen hamilton heb weve even seen utsa invest 70 cybersecur center school data scienc built program specif meet grow demand thi industryour program 18 week long fulltim handson projectbas curriculum develop instruct led senior data scientist maggi giust ha work heb capit group rackspac along input dozen practition hire partner student work real data set realist problem entir data scienc pipelin collect deploy receiv profession develop train resum write interview continu educ prepar smooth transit workforcew focu appli data scienc immedi impact roi busi back 6 month tuition refund guarante like exist web dev program focus data scienc python sql ml cover 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel data 14 domain expertis developmentappl open codeup first data scienc cohort start class februari 4 2019 hurri onli 25 seat avail mission cultiv inclus growth scholarship avail woman minor lgbtqia individu veteran first respond peopl reloc san antonioif want learn join program hire graduat email datasciencecodeupcom'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(remove_stopwords(article_lemmatize)))\n",
    "article_stopwords_removed = remove_stopwords(article_lemmatize)\n",
    "article_stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rumors true time arrived codeup officially opened applications new data science career accelerator 25 seats available immersive program one kind san antonio help land job glassdoors 1 best job americadata science method providing actionable intelligence data data revolution hit san antonio resulting explosion data scientist positions across companies like usaa accenture booz allen hamilton heb weve even seen utsa invest 70 cybersecurity center school data science built program specifically meet growing demands industryour program 18 weeks long fulltime handson projectbased curriculum development instruction led senior data scientist maggie giust worked heb capital group rackspace along input dozens practitioners hiring partners students work real data sets realistic problems entire data science pipeline collection deployment receive professional development training resume writing interviewing continuing education prepare smooth transition workforcewe focus applied data science immediate impact roi business back 6 month tuition refund guarantee like existing web dev program focusing data science python sql ml covered 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling data 14 domain expertise developmentapplications open codeups first data science cohort start class february 4 2019 hurry 25 seats available mission cultivating inclusive growth scholarships available women minorities lgbtqia individuals veterans first responders people relocating san antonioif want learn joining program hiring graduates email datasciencecodeupcom'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test my function for adding extra_words to my stopword list and removing exclude_words. \n",
    "\n",
    "remove_stopwords(article, extra_words=['German'], exclude_words=['i', 'me'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Moderna's early data shows its COVID-19 vaccin...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>American biotechnology company Moderna on Mond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Lakshmi Vilas Bank withdrawals capped at ₹25,0...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>The Centre has imposed a 30-day moratorium on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Pfizer shares drop 4.5% as Moderna says its va...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>Pfizer’s shares fell as much as 4.5% on Monday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>How does Moderna's COVID-19 vaccine candidate ...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Moderna's initial results of late-stage trial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Musk gets $15bn richer in 2 hours, becomes wor...</td>\n",
       "      <td>Krishna Veera Vanamali</td>\n",
       "      <td>Billionaire Elon Musk added $15 billion to his...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                              title  \\\n",
       "0  business  Moderna's early data shows its COVID-19 vaccin...   \n",
       "1  business  Lakshmi Vilas Bank withdrawals capped at ₹25,0...   \n",
       "2  business  Pfizer shares drop 4.5% as Moderna says its va...   \n",
       "3  business  How does Moderna's COVID-19 vaccine candidate ...   \n",
       "4  business  Musk gets $15bn richer in 2 hours, becomes wor...   \n",
       "\n",
       "                   author                                            content  \n",
       "0          Pragya Swastik  American biotechnology company Moderna on Mond...  \n",
       "1          Pragya Swastik  The Centre has imposed a 30-day moratorium on ...  \n",
       "2  Krishna Veera Vanamali  Pfizer’s shares fell as much as 4.5% on Monday...  \n",
       "3          Pragya Swastik  Moderna's initial results of late-stage trial ...  \n",
       "4  Krishna Veera Vanamali  Billionaire Elon Musk added $15 billion to his...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = a.get_news_articles()\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust\\nData Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou\\nA week ago, Codeup launch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>SA Tech Job Fair\\nThe third bi-annual San Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1  By Dimitri Antoniou and Maggie Giust\\nData Sci...  \n",
       "2  By Dimitri Antoniou\\nA week ago, Codeup launch...  \n",
       "3  SA Tech Job Fair\\nThe third bi-annual San Anto...  \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "    'https://codeup.com/data-science-myths/',\n",
    "    'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "    'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "    'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/']\n",
    "\n",
    "codeup_df = a.get_blog_articles(urls)\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
